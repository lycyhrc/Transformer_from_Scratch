{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keypoints\n",
    "\n",
    "üíª The multi-head attention mechanism is a crucial component of the Transformer architecture, and understanding its theory and implementation is essential for coding it effectively.\n",
    "\n",
    "üí° The multi-head attention system generates multiple attention matrices, each representing a probability distribution, to capture different aspects of the input sequence.\n",
    "\n",
    "üß† The head dimension in multi-head attention exists because it combines the query, key, and value vectors, allowing for parallel operations on the sequences.\n",
    "\n",
    "üßØ Combining multiple heads in a transformer neural network allows them to communicate with each other, resulting in a more context-aware output vector.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 4\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "x = torch.randn((batch_size, sequence_length, input_dim)) # x : bt_size, seq_len, input_dim\n",
    "x.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ËæìÂÖ•Êï∞ÊçÆÂΩ¢Áä∂‰∏∫ `(batch_size, sequence_length, input_dim)`„ÄÇËøôË°®Á§∫Âú®ÊØè‰∏™epochs‰∏≠ÔºåÊúâ batch_size ‰∏™Ê†∑Êú¨ÔºåÊØè‰∏™Ê†∑Êú¨ÊòØ‰∏Ä‰∏™ÈïøÂ∫¶‰∏∫ sequence_length ÁöÑÂ∫èÂàóÔºåÊØè‰∏™ÂÖÉÁ¥†ÁöÑÁª¥Â∫¶‰∏∫ input_dim„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3 * d_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÈ¢òÔºö‰∏∫‰ªÄ‰πàË¶ÅÂÆö‰πâ‰∏Ä‰∏™ÂÖ®ËøûÊé•Â±ÇÔºåËÄå‰∏îËæìÂá∫Áª¥Â∫¶‰∏∫‰ªÄ‰πàÊòØ 3 * d_modelÔºü**\n",
    "\n",
    "Á≠îÊ°àÔºöÂõ†‰∏∫ÈúÄË¶Å‰ªéÂêå‰∏Ä‰∏™ËæìÂÖ• x ÁîüÊàê‰∏â‰∏™‰∏çÂêåÁöÑÂêëÈáèÔºöÊü•ËØ¢ÔºàQueryÔºâ„ÄÅÈîÆÔºàKeyÔºâÂíåÂÄºÔºàValueÔºâ„ÄÇËøô‰∏â‰∏™ÂêëÈáèÈÉΩÈÄöËøá qkv_layer ÁîüÊàêÔºåÊâÄ‰ª• qkv_layer ÁöÑËæìÂá∫ÂÆûÈôÖ‰∏äÊòØËøô‰∏â‰∏™ÂêëÈáèÁöÑÈõÜÂêà„ÄÇ(‰∏ÄÊ¨°ÁîüÊàêÔºåÂêéÁª≠ÂàÜÂºÄ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv_layer(x)  # linearÂè™ÊúâÊúÄ‰ºöÁª¥Â∫¶ËøõË°åÂèòÂåñ Ôºà*ÔºåH_inÔºâ---> (*,H_out)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins = 200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) *3\n",
    "plt.bar(x_val, y_val, align='center',color=['forestgreen'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÈ¢òÔºö‰∏∫‰ªÄ‰πàË¶ÅÊü•Áúã qkv ÁöÑÂàÜÂ∏ÉÔºü**\n",
    "\n",
    "Á≠îÊ°àÔºöÊü•Áúã qkv ÁöÑÂàÜÂ∏ÉÊúâÂä©‰∫éÊàë‰ª¨ÁêÜËß£Ê®°ÂûãÁöÑÂÜÖÈÉ®Áä∂ÊÄÅÂíåË°å‰∏∫„ÄÇ‰æãÂ¶ÇÔºåÂ¶ÇÊûúÂàÜÂ∏ÉÈùûÂ∏∏ÂÅèÊñúÊàñÈõÜ‰∏≠Âú®Êüê‰∏™ÁâπÂÆöÁöÑËåÉÂõ¥ÂÜÖÔºåÈÇ£‰πàÂèØËÉΩÈúÄË¶ÅË∞ÉÊï¥Ê®°ÂûãÂèÇÊï∞Êàñ‰ΩøÁî®‰∏çÂêåÁöÑÂàùÂßãÂåñÁ≠ñÁï•„ÄÇÊ≠§Â§ñÔºåËøô‰πüÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨Ë∞ÉËØïÊ®°ÂûãÔºåÁ°ÆËÆ§ÊòØÂê¶ÊúâÊÑèÂ§ñÁöÑË°å‰∏∫ÔºàÂ¶ÇÂÄºÁöÑÁàÜÁÇ∏ÊàñÊ∂àÂ§±Ôºâ„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÔºöqkvÂè™ÊòØ‰∏Ä‰∏™[1, 4, 1536]Á¨¨ÂêëÈáèÔºåÂ¶Ç‰ΩïËÆ°ÁÆóÂàÜÂ∏ÉÁöÑÔºü**\n",
    "\n",
    "torch.histc ÂáΩÊï∞‰ºöÂ∞ÜÂº†ÈáèËßÜ‰∏∫‰∏Ä‰∏™‰∏ÄÁª¥ÁöÑÊï∞ÊçÆÊµÅÔºåÂπ∂ÂØπÊâÄÊúâÁöÑÊï∞ÊçÆÁÇπËøõË°åÁªüËÆ°„ÄÇ\n",
    "\n",
    "‰∏∫‰∫ÜÊõ¥Â•ΩÂú∞ÁêÜËß£Ëøô‰∏™ËøáÁ®ãÔºåÊàë‰ª¨ÂèØ‰ª•Â∞ÜÂÖ∂ÊãÜËß£‰∏∫‰ª•‰∏ãÊ≠•È™§Ôºö\n",
    "\n",
    "È¶ñÂÖàÔºåtorch.histc ÂáΩÊï∞‰ºöÂ∞Ü qkv Âº†Èáè‰∏≠ÁöÑÊâÄÊúâÂÖÉÁ¥†ÊãâÂπ≥Êàê‰∏Ä‰∏™‰∏ÄÁª¥ÁöÑÊï∞ÁªÑ„ÄÇÂú®‰æãÂ≠ê‰∏≠ÔºåÂæóÂà∞‰∏Ä‰∏™ÂÖ∑Êúâ 1 * 4 * 1536 = 6144 ‰∏™ÂÖÉÁ¥†ÁöÑÊï∞ÁªÑ„ÄÇ\n",
    "Êé•ÁùÄÔºåtorch.histc ÂáΩÊï∞‰ºöÂØπËøô‰∏™Êï∞ÁªÑ‰∏≠ÁöÑÂÖÉÁ¥†ËøõË°åÂàÜÁÆ±ÁªüËÆ°„ÄÇbins ÂèÇÊï∞ÂÆö‰πâ‰∫ÜÂàÜÁÆ±ÁöÑÊï∞ÈáèÔºåmin Âíå max ÂèÇÊï∞ÂÆö‰πâ‰∫ÜÂàÜÁÆ±ÁöÑËåÉÂõ¥„ÄÇÂú®‰Ω†ÁöÑ‰æãÂ≠ê‰∏≠ÔºåËøôÂ∞ÜÊääÊâÄÊúâÁöÑÂÖÉÁ¥†ÂàÜÂà∞ 200 ‰∏™ÁÆ±Â≠ê‰∏≠ÔºåÊØè‰∏™ÁÆ±Â≠êÁöÑËåÉÂõ¥ÊòØ (-3, 3)„ÄÇ\n",
    "ÊúÄÂêéÔºåtorch.histc ÂáΩÊï∞‰ºöËøîÂõû‰∏Ä‰∏™Êï∞ÁªÑÔºåÂÖ∂‰∏≠ÊØè‰∏™ÂÖÉÁ¥†Ë°®Á§∫ÂØπÂ∫îÁÆ±Â≠ê‰∏≠ÁöÑÂÖÉÁ¥†Êï∞Èáè„ÄÇ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model // num_heads # 1536/8 = 192\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)\n",
    "qkv.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "qkv Ë¢´ÈáçÂ°ëÂíåÊãÜÂàÜÊàê num_heads ‰∏™Â§¥ÔºåÊØè‰∏™Â§¥ÁöÑÁª¥Â∫¶ÊòØ head_dim„ÄÇÊØè‰∏™Â§¥‰ΩøÁî®ÁöÑ q„ÄÅk„ÄÅv ÊòØÂÖ®‰Ωì q„ÄÅk„ÄÅv ÁªèËøáÁ∫øÊÄßÂèòÊç¢ÂêéÁöÑÈÉ®ÂàÜÊï∞ÊçÆÔºåËÄå‰∏çÊòØÁõ¥Êé•‰ªéÂéüÂßãÁöÑ q„ÄÅk„ÄÅv ‰∏≠Âèñ‰∏ÄÈÉ®ÂàÜ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÈ¢òÔºö‰∏∫‰ªÄ‰πàË¶ÅÊîπÂèò qkv ÁöÑÂΩ¢Áä∂Ôºü**\n",
    "\n",
    "Á≠îÊ°àÔºöÂú®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂‰∏≠ÔºåËæìÂÖ•ÁöÑ d_model Áª¥Â∫¶ÁöÑÊï∞ÊçÆ‰ºöË¢´ÂàÜÊàêÂ§ö‰∏™‚ÄúÂ§¥‚ÄùÔºåÊØè‰∏™Â§¥Â§ÑÁêÜ‰∏ÄÈÉ®ÂàÜ‰ø°ÊÅØ„ÄÇËøôÊ†∑ÂèØ‰ª•ËÆ©Ê®°ÂûãÂú®Â§ÑÁêÜËæìÂÖ•Êó∂Êõ¥Âä†ÁÅµÊ¥ªÔºåÂõ†‰∏∫ÊØè‰∏™Â§¥ÂèØ‰ª•Â≠¶‰π†Âπ∂‰∏ìÊ≥®‰∫éÊçïËé∑‰∏çÂêåÁöÑ‰ø°ÊÅØ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÈ¢òÔºö‰∏∫‰ªÄ‰πàÂú®ÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶‰∏äÂ∞ÜÊï∞ÊçÆÂàíÂàÜ‰∏∫‰∫Ü num_heads ‰∏™ÈÉ®ÂàÜÔºü**\n",
    "\n",
    "Á≠îÊ°àÔºöÂú®Ê∑±Â∫¶Â≠¶‰π†Ê®°Âûã‰∏≠ÔºåÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶ÈÄöÂ∏∏Áî®Êù•Ë°®Á§∫Êï∞ÊçÆÁöÑÁâπÂæÅÔºåËÄåÂâçÈù¢ÁöÑÁª¥Â∫¶ÂàôÁî®Êù•Ë°®Á§∫Êï∞ÊçÆÁöÑÁªìÊûÑ„ÄÇÂú®Ëøô‰∏™‰∏ä‰∏ãÊñá‰∏≠Ôºånum_heads ÊòØÊàë‰ª¨ÁöÑ‚ÄúÂ§¥‚ÄùÁöÑÊï∞ÈáèÔºåÊØè‰∏™‚ÄúÂ§¥‚ÄùÈÉΩÈúÄË¶ÅÂ§ÑÁêÜ‰∏ÄÈÉ®ÂàÜÁâπÂæÅ„ÄÇÂõ†Ê≠§ÔºåÊàë‰ª¨Âú®ÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶‰∏äÂ∞ÜÊï∞ÊçÆÂàíÂàÜ‰∏∫‰∫Ü num_heads ‰∏™ÈÉ®ÂàÜ„ÄÇ\n",
    "\n",
    "ËøôÊ†∑ÂÅöÁöÑÂ•ΩÂ§ÑÊòØÔºåÂèØ‰ª•ËÆ©Êàë‰ª¨Âú®ÂêéÁª≠ÁöÑËÆ°ÁÆó‰∏≠ÔºåÊõ¥Êñπ‰æøÂú∞Â§ÑÁêÜÊØè‰∏™‚ÄúÂ§¥‚ÄùÁöÑÊï∞ÊçÆ„ÄÇ‰æãÂ¶ÇÔºåÂΩìÊàë‰ª¨ÈúÄË¶ÅËÆ°ÁÆóÊØè‰∏™‚ÄúÂ§¥‚ÄùÁöÑÊ≥®ÊÑèÂäõÊùÉÈáçÊó∂ÔºåÊàë‰ª¨ÂèØ‰ª•Áõ¥Êé•ÂØπÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶ÔºàÂç≥ 3 * head_dimÔºâËøõË°åÊìç‰ΩúÔºåËÄå‰∏çÈúÄË¶ÅÂÖ≥ÂøÉ‚ÄúÂ§¥‚ÄùÁöÑÊï∞Èáè„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0,2,1,3)\n",
    "qkv.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÈÄöËøáÂ∞Ü qkv ÁöÑÁª¥Â∫¶ÈáçÊéíÂàó‰∏∫ `(batch_size, num_heads, sequence_length, 3 * head_dim)`ÔºåÊàë‰ª¨ÂèØ‰ª•Êõ¥Êñπ‰æøÂú∞Â§ÑÁêÜÊØè‰∏™Â§¥ÁöÑÊï∞ÊçÆÔºåÂõ†‰∏∫Áé∞Âú®ÊØè‰∏™Â§¥ÁöÑÊï∞ÊçÆÈÉΩÂú®ËøûÁª≠ÁöÑÂÜÖÂ≠ò‰ΩçÁΩÆ‰∏≠„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim = -1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention for multiple heads\n",
    "\n",
    "For a single head:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { self attention } & =\\operatorname{softmax}\\left(\\frac{Q \\cdot K^T}{\\sqrt{d_k}}+M\\right) \\\\\n",
    "\\text { new } \\mathrm{V} & =\\text { self attention. } V\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # 1Ôºå8Ôºå4Ôºå64 * 1Ôºå8Ôºå64Ôºå4 ---> 1,8,4,4\n",
    "scaled.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÈ¢òÔºö‰∏∫‰ªÄ‰πàË¶ÅËÆ°ÁÆóÁº©ÊîæÁöÑÁÇπÁßØÊ≥®ÊÑèÂäõÔºå‰ª•Âèä‰∏∫‰ªÄ‰πàË¶ÅÂØπÁªìÊûúËøõË°åÁº©ÊîæÔºü**\n",
    "\n",
    "Á≠îÊ°àÔºöÂú® Transformer Ê®°ÂûãÁöÑÊ≥®ÊÑèÂäõÊú∫Âà∂‰∏≠ÔºåÊàë‰ª¨‰ΩøÁî®Êü•ËØ¢ `q` ÂíåÈîÆ `k` ÁöÑÁÇπÁßØÊù•ËÆ°ÁÆóÊ≥®ÊÑèÂäõÊùÉÈáç„ÄÇÁÑ∂ËÄåÔºåÂΩìÊü•ËØ¢ÂíåÈîÆÁöÑÁª¥Â∫¶ $d_k$ ËæÉÂ§ßÊó∂ÔºåÁÇπÁßØÁöÑÁªìÊûúÂèØËÉΩ‰ºöÈùûÂ∏∏Â§ßÔºåËøô‰ºöÂØºËá¥ softmax ÂáΩÊï∞ÔºàÈÄöÂ∏∏Áî®‰∫éËÆ°ÁÆóÊ≥®ÊÑèÂäõÊùÉÈáçÔºâÂú®ÂèçÂêë‰º†Êí≠Êó∂Ê¢ØÂ∫¶Ê∂àÂ§±Ôºå‰ªéËÄåÂΩ±ÂìçÊ®°ÂûãÁöÑËÆ≠ÁªÉ„ÄÇ\n",
    "\n",
    "‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜÁº©ÊîæÂõ†Â≠ê $1/\\sqrt(d_k)$„ÄÇËøô‰∏™Áº©ÊîæÂõ†Â≠êÂèØ‰ª•Á°Æ‰øùÁÇπÁßØÁöÑÁªìÊûúÂú®‰∏Ä‰∏™ÂêàÁêÜÁöÑËåÉÂõ¥ÂÜÖÔºå‰ªéËÄåÈÅøÂÖç softmax ÂáΩÊï∞ÁöÑÊ¢ØÂ∫¶Ê∂àÂ§±ÈóÆÈ¢ò„ÄÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaled ÁöÑÂΩ¢Áä∂ `(batch_size, num_heads, sequence_length, sequence_length)`„ÄÇÂõ†‰∏∫ËøôÊòØÂú®ÊúÄÂêé‰∏§‰∏™Áª¥Â∫¶‰∏äËøõË°åÁöÑÁü©Èòµ‰πòÊ≥ïÔºåÂç≥ÂØπ‰∫éÊØè‰∏™Â§¥ÂíåÊØè‰∏™ÊâπÊ¨°ÁöÑÊï∞ÊçÆÔºåÊàë‰ª¨ÈÉΩËÆ°ÁÆó‰∫ÜÊâÄÊúâÊü•ËØ¢ÂíåÈîÆÁöÑÁÇπÁßØ„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[ 0.9286, -0.2131, -1.0884],\n",
      "        [ 1.2531,  0.7147, -0.6907]])\n",
      "y transpose: tensor([[ 0.9286,  1.2531],\n",
      "        [-0.2131,  0.7147],\n",
      "        [-1.0884, -0.6907]])\n"
     ]
    }
   ],
   "source": [
    "# Ë°•ÂÖÖ\n",
    "y = torch.randn(2, 3)\n",
    "print(f\"y: {y}\")\n",
    "print(f\"y transpose: {torch.transpose(y, 1, 0)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÈ¢òÔºö‰∏∫‰ªÄ‰πàÂ§öÁª¥Â∫¶Âº†ÈáèÈúÄË¶Å‰ΩøÁî® PyTorch ÁöÑ transpose Êàñ permute ÂáΩÊï∞ËøõË°åËΩ¨ÁΩÆÔºåËÄå‰∏çËÉΩ‰ΩøÁî® NumPy ÁöÑ T Â±ûÊÄßÔºü**\n",
    "\n",
    "Á≠îÊ°àÔºöNumPy ÁöÑ T Â±ûÊÄßÂíå transpose ÂáΩÊï∞Âú®Â§ÑÁêÜ‰∫åÁª¥Êï∞ÁªÑÔºàÂç≥Áü©ÈòµÔºâÊó∂Ë°®Áé∞ÂæóÂæàÂ•ΩÔºåÂÆÉ‰ª¨ÂèØ‰ª•Â∞Ü‰∫åÁª¥Êï∞ÁªÑÁöÑË°åÂíåÂàóËøõË°å‰∫§Êç¢„ÄÇÁÑ∂ËÄåÔºåÂØπ‰∫éÈ´ò‰∫é‰∫åÁª¥ÁöÑÊï∞ÁªÑÔºåT Â±ûÊÄßÂè™‰ºöÂèçËΩ¨Áª¥Â∫¶ÁöÑÈ°∫Â∫èÔºåËøôÂèØËÉΩÂπ∂‰∏çÊòØÊàë‰ª¨ÊÉ≥Ë¶ÅÁöÑÁªìÊûú„ÄÇ\n",
    "\n",
    "‰æãÂ¶ÇÔºåÂØπ‰∫é‰∏Ä‰∏™ÂΩ¢Áä∂‰∏∫ (a, b, c) ÁöÑ‰∏âÁª¥Êï∞ÁªÑÔºåT Â±ûÊÄß‰ºöÂæóÂà∞‰∏Ä‰∏™ÂΩ¢Áä∂‰∏∫ (c, b, a) ÁöÑÊï∞ÁªÑ„ÄÇ‰ΩÜÂú®ËÆ∏Â§öÊÉÖÂÜµ‰∏ãÔºåÊàë‰ª¨ÂèØËÉΩÂ∏åÊúõ‰∫§Êç¢ÂÖ∂‰ªñ‰∏§‰∏™Áª¥Â∫¶ÔºåÂ¶Ç (a, c, b) Êàñ (b, a, c)ÔºåËøôÊó∂Â∞±ÈúÄË¶Å‰ΩøÁî® transpose Êàñ permute ÂáΩÊï∞‰∫Ü„ÄÇ\n",
    "\n",
    "PyTorch ÁöÑ transpose Âíå permute ÂáΩÊï∞Êèê‰æõ‰∫ÜÊõ¥Âº∫Â§ßÁöÑÂäüËÉΩÔºåÂÆÉ‰ª¨ÂèØ‰ª•‰∫§Êç¢Âº†ÈáèÁöÑ‰ªªÊÑè‰∏§‰∏™Áª¥Â∫¶ÔºåÊàñËÄÖÈáçÊñ∞ÊéíÂàóÊâÄÊúâÁª¥Â∫¶ÁöÑÈ°∫Â∫è„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All head masked: tensor([[[[0., -inf, -inf, -inf],\n",
      "          [0., 0., -inf, -inf],\n",
      "          [0., 0., 0., -inf],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., -inf, -inf, -inf],\n",
      "          [0., 0., -inf, -inf],\n",
      "          [0., 0., 0., -inf],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., -inf, -inf, -inf],\n",
      "          [0., 0., -inf, -inf],\n",
      "          [0., 0., 0., -inf],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., -inf, -inf, -inf],\n",
      "          [0., 0., -inf, -inf],\n",
      "          [0., 0., 0., -inf],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., -inf, -inf, -inf],\n",
      "          [0., 0., -inf, -inf],\n",
      "          [0., 0., 0., -inf],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., -inf, -inf, -inf],\n",
      "          [0., 0., -inf, -inf],\n",
      "          [0., 0., 0., -inf],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., -inf, -inf, -inf],\n",
      "          [0., 0., -inf, -inf],\n",
      "          [0., 0., 0., -inf],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., -inf, -inf, -inf],\n",
      "          [0., 0., -inf, -inf],\n",
      "          [0., 0., 0., -inf],\n",
      "          [0., 0., 0., 0.]]]])\n",
      "Single head masked: tensor([[0., -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf],\n",
      "        [0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "## ÁîüÊàêmasked\n",
    "mask = torch.full(scaled.size(), float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "print(f\"All head masked: {mask}\")\n",
    "print(f\"Single head masked: {mask[0][1]}\") # mask for input to a single head"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÈ¢òÔºömask[0][1] ÂÖ∑‰ΩìË°®Á§∫‰ªÄ‰πàÔºü**\n",
    "\n",
    "Á≠îÊ°àÔºöÂú®Ëøô‰∏™‰∏ä‰∏ãÊñá‰∏≠Ôºåmask[0][1] Áî®‰∫éÈÄâÊã© mask Âº†Èáè‰∏≠Á¨¨‰∏Ä‰∏™ÊâπÊ¨°ÔºàbatchÔºâÁöÑÁ¨¨‰∫å‰∏™Â§¥ÔºàheadÔºâÁöÑÈÅÆÁΩ©„ÄÇÂú®Â§öÂ§¥Ê≥®ÊÑèÂäõÊú∫Âà∂‰∏≠ÔºåÊØè‰∏™ÊâπÊ¨°ÂåÖÂê´Â§ö‰∏™Â§¥ÔºåÊØè‰∏™Â§¥ÈÉΩÊúâËá™Â∑±ÁöÑÊü•ËØ¢„ÄÅÈîÆÂíåÂÄºÂêëÈáèÔºå‰ª•ÂèäÂØπÂ∫îÁöÑÈÅÆÁΩ©„ÄÇËøôÈáåÔºåmask[0][1] Â∞±ÊòØÈÄâÊã©‰∫ÜÁ¨¨‰∏Ä‰∏™ÊâπÊ¨°ÁöÑÁ¨¨‰∫å‰∏™Â§¥ÁöÑÈÅÆÁΩ©„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2548,    -inf,    -inf,    -inf],\n",
       "        [ 0.7148,  0.7982,    -inf,    -inf],\n",
       "        [ 0.0151,  0.1546,  0.6325,    -inf],\n",
       "        [-0.2733, -0.6332, -0.1531,  0.1882]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask) [0][0] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ÈóÆÈ¢òÔºö‰∏∫‰ªÄ‰πàÈúÄË¶ÅÂàõÂª∫ËøôÊ†∑ÁöÑ mask Âº†ÈáèÔºåÂÆÉÁöÑ‰ΩúÁî®ÊòØ‰ªÄ‰πàÔºü**\n",
    "\n",
    "Á≠îÊ°àÔºöËøô‰∏™ mask Âº†ÈáèÊòØÁî®‰∫éÈÅÆÁΩ©Â∫èÂàóÁöÑ‰∏ÄÈÉ®ÂàÜÔºåÈò≤Ê≠¢Ê®°ÂûãÁúãÂà∞Â∫èÂàóÁöÑÊú™Êù•‰ø°ÊÅØ„ÄÇÂú®Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°‰∏≠ÔºåÁâπÂà´ÊòØÂú®ËÆ≠ÁªÉËØ≠Ë®ÄÊ®°ÂûãÊó∂ÔºåÊàë‰ª¨Â∏åÊúõÊ®°ÂûãÂú®È¢ÑÊµã‰∏ã‰∏Ä‰∏™ËØçÊó∂ÔºåÂè™ËÉΩÁúãÂà∞ÂΩìÂâçËØçÂèäÂÖ∂‰πãÂâçÁöÑËØçÔºåËÄå‰∏çËÉΩÁúãÂà∞Êú™Êù•ÁöÑËØç„ÄÇËøôÊ†∑ÁöÑÈÅÆÁΩ©ÂèØ‰ª•Â∏ÆÂä©Êàë‰ª¨ÂÆûÁé∞Ëøô‰∏™ÁõÆÊ†á„ÄÇ\n",
    "\n",
    "ÂÖ∑‰ΩìÊù•ËØ¥Ôºåmask Âº†ÈáèÁöÑ‰∏ä**‰∏âËßíÈÉ®ÂàÜÊòØË¥üÊó†Á©∑ÔºåË°®Á§∫Â∫èÂàóÁöÑÊú™Êù•‰ø°ÊÅØÔºõ‰∏ã‰∏âËßíÈÉ®ÂàÜÊòØÈõ∂**ÔºåË°®Á§∫Â∫èÂàóÁöÑÂΩìÂâçÂíåËøáÂéªÁöÑ‰ø°ÊÅØ„ÄÇÂΩìÊàë‰ª¨Âú®ËÆ°ÁÆóÊ≥®ÊÑèÂäõÊùÉÈáçÊó∂ÔºåÂ∞ÜËøô‰∏™ mask Ê∑ªÂä†Âà∞ scaled ‰∏äÔºåÂõ†‰∏∫ softmax ÂáΩÊï∞ÂØπ‰∫éË¥üÊó†Á©∑ÁöÑËæìÂÖ•‰ºöËæìÂá∫Èõ∂ÔºåÊâÄ‰ª•Ê®°ÂûãÂ∞±Êó†Ê≥ïÁúãÂà∞Â∫èÂàóÁöÑÊú™Êù•‰ø°ÊÅØ‰∫Ü„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scaled + mask # multi head  attention score matrix with masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4792, 0.5208, 0.0000, 0.0000],\n",
       "        [0.2498, 0.2871, 0.4631, 0.0000],\n",
       "        [0.2266, 0.1582, 0.2556, 0.3596]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = F.softmax(scaled, dim=-1)  # scaled to [0, 1]\n",
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention size: torch.Size([1, 8, 4, 4]), values size: torch.Size([1, 8, 4, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"attention size: {attention.size()}, values size: {v.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v) # attention score * values\n",
    "values.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k=q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1,-2))/math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled,dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=None)\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2764, 0.2697, 0.2149, 0.2389],\n",
       "        [0.2994, 0.3255, 0.1295, 0.2455],\n",
       "        [0.2013, 0.2314, 0.3732, 0.1941],\n",
       "        [0.2266, 0.1582, 0.2556, 0.3596]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size, sequence_length, num_heads*head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=512, bias=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer = nn.Linear(d_model,d_model)\n",
    "linear_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = linear_layer(values)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3412,  0.2449,  0.2114,  ..., -0.2294,  0.0139,  0.0105],\n",
       "         [-0.1401,  0.0268, -0.0720,  ..., -0.1523,  0.2122,  0.0164],\n",
       "         [-0.0465,  0.1051, -0.0417,  ...,  0.1026,  0.1103, -0.0321],\n",
       "         [-0.0727, -0.0463,  0.0377,  ..., -0.1145,  0.2986,  0.2640]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (All) MultiheadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k ,v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.head_dim = d_model //num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim, 3*d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask = None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3*self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "\n",
    "        qkv  = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "\n",
    "        q, k, v = qkv.chunk(3, dim = -1)\n",
    "        print(f\"q size:{q.size()}, k size:{k.size()}, v size:{v.size()}\")\n",
    "\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention size: {attention.size()}\")\n",
    "\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads*self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input without mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size:torch.Size([30, 8, 5, 64]), k size:torch.Size([30, 8, 5, 64]), v size:torch.Size([30, 8, 5, 64])\n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention size: torch.Size([30, 8, 5, 5])\n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn((batch_size, sequence_length, input_dim))\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.5284e-02,  1.2722e-01,  2.4985e-01,  ..., -2.1212e-01,\n",
       "          -1.4147e-01,  5.2860e-02],\n",
       "         [-1.2464e-01, -1.4993e-01, -1.1479e-01,  ..., -2.9906e-02,\n",
       "          -6.3602e-03,  1.9076e-01],\n",
       "         [-1.1769e-01, -9.4000e-02,  9.0091e-02,  ...,  8.0865e-02,\n",
       "           4.6137e-02, -1.1308e-01],\n",
       "         [ 8.9524e-02,  5.5354e-02, -3.9023e-02,  ...,  3.1260e-02,\n",
       "          -1.2758e-01, -3.8482e-02],\n",
       "         [-1.5184e-01, -5.3139e-02, -1.8266e-01,  ..., -1.0104e-01,\n",
       "           3.0766e-01,  1.0210e-01]],\n",
       "\n",
       "        [[-5.6526e-02,  3.8834e-01, -1.2390e-02,  ..., -5.9704e-02,\n",
       "           2.3768e-01, -2.9467e-02],\n",
       "         [ 1.2905e-01,  2.2574e-02,  7.2760e-02,  ...,  3.4676e-03,\n",
       "          -6.2535e-02,  1.4201e-01],\n",
       "         [ 1.7856e-01, -4.9391e-02,  6.3659e-02,  ..., -1.6452e-01,\n",
       "          -9.0021e-02, -1.3106e-01],\n",
       "         [ 1.4727e-01,  9.4759e-03, -2.9079e-01,  ...,  5.3035e-02,\n",
       "          -1.2689e-01,  2.4708e-01],\n",
       "         [-2.3948e-02,  3.7071e-02, -8.5224e-02,  ..., -6.0736e-02,\n",
       "          -4.0356e-02, -2.0263e-01]],\n",
       "\n",
       "        [[-9.9209e-02,  1.4457e-01,  1.2916e-01,  ..., -1.3547e-01,\n",
       "           2.9630e-01, -1.3439e-01],\n",
       "         [ 2.0039e-01, -1.7372e-01,  7.3501e-02,  ..., -2.1457e-01,\n",
       "          -7.8606e-02, -2.2041e-01],\n",
       "         [-1.0347e-02,  6.2543e-03,  1.2217e-01,  ..., -3.8167e-01,\n",
       "          -9.1258e-02, -1.2748e-01],\n",
       "         [ 7.3079e-02, -1.4386e-01, -1.3951e-02,  ..., -1.7582e-01,\n",
       "           5.1970e-02,  5.1082e-02],\n",
       "         [-7.4195e-02, -3.7951e-03, -6.0524e-02,  ..., -1.0862e-01,\n",
       "          -2.0819e-03,  1.7469e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.2739e-01, -4.0455e-02,  2.0003e-01,  ...,  2.0781e-01,\n",
       "           8.3078e-02,  1.4658e-01],\n",
       "         [-1.4010e-01, -1.8082e-01,  6.8605e-02,  ...,  4.8183e-03,\n",
       "          -7.9992e-02,  9.1744e-02],\n",
       "         [-1.4348e-01, -2.8711e-02, -6.9014e-02,  ..., -8.9810e-02,\n",
       "           1.7543e-01,  3.8294e-04],\n",
       "         [-2.8533e-02,  4.4199e-03,  8.1753e-02,  ..., -2.6650e-01,\n",
       "          -6.1190e-02,  1.6527e-01],\n",
       "         [ 9.3710e-02,  1.1338e-02, -1.1004e-02,  ...,  4.5200e-02,\n",
       "           2.1608e-01, -1.0056e-01]],\n",
       "\n",
       "        [[-9.1423e-02,  2.4725e-01, -2.5480e-01,  ...,  7.3778e-02,\n",
       "          -3.7986e-01, -4.4736e-02],\n",
       "         [-2.8415e-01, -2.8046e-02,  1.3098e-01,  ..., -2.2916e-01,\n",
       "          -8.6993e-02, -6.3826e-02],\n",
       "         [ 2.4611e-01, -1.8869e-01,  3.5635e-01,  ...,  1.1057e-02,\n",
       "          -3.1153e-01, -8.1883e-02],\n",
       "         [-7.7056e-02, -7.9658e-02,  1.6744e-01,  ..., -9.7499e-02,\n",
       "           1.0359e-01, -5.0383e-02],\n",
       "         [-1.2270e-01,  1.4218e-01,  8.5103e-02,  ...,  2.4662e-01,\n",
       "          -8.8586e-04, -4.5084e-02]],\n",
       "\n",
       "        [[-2.6870e-01,  1.6422e-01,  4.7651e-02,  ..., -4.9240e-02,\n",
       "           3.5884e-01, -5.4511e-02],\n",
       "         [ 1.7895e-01,  1.7038e-01,  4.1670e-02,  ...,  1.3283e-01,\n",
       "          -2.7424e-01,  1.1805e-01],\n",
       "         [ 2.4595e-01, -3.6187e-02,  1.3643e-01,  ...,  1.1451e-01,\n",
       "           1.0459e-01, -8.9542e-02],\n",
       "         [ 9.0449e-02,  3.3295e-02, -2.9386e-01,  ..., -8.6094e-02,\n",
       "          -1.0355e-01, -2.8783e-02],\n",
       "         [-1.1242e-01,  1.1759e-01, -1.1835e-01,  ..., -9.4781e-02,\n",
       "          -3.0517e-02,  1.1291e-01]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input with mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size:torch.Size([30, 8, 5, 64]), k size:torch.Size([30, 8, 5, 64]), v size:torch.Size([30, 8, 5, 64])\n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention size: torch.Size([30, 8, 5, 5])\n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "# x = torch.randn((batch_size, sequence_length, input_dim))  add masked\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "\n",
    "mask = (torch.triu(torch.ones((batch_size, 1, sequence_length, sequence_length))) == 1).transpose(-1, -2)\n",
    "mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "\n",
    "out = model.forward(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3427e-01,  1.8508e-03,  3.1447e-01,  ..., -3.6402e-01,\n",
       "           1.1125e-01, -2.2567e-02],\n",
       "         [-1.1818e-01,  8.7459e-02,  1.8139e-01,  ...,  1.9198e-01,\n",
       "           9.0766e-02,  3.3462e-01],\n",
       "         [ 3.8551e-01, -2.0970e-02, -1.3621e-02,  ...,  6.1666e-02,\n",
       "          -1.3019e-02,  1.5994e-01],\n",
       "         [ 1.2894e-01,  2.1139e-01, -6.2112e-02,  ...,  5.1420e-02,\n",
       "           8.0267e-02,  1.4966e-01],\n",
       "         [-6.8595e-01,  3.3024e-01, -1.0399e-01,  ..., -3.8271e-01,\n",
       "           8.9425e-02, -1.1681e-01]],\n",
       "\n",
       "        [[ 8.5313e-02,  2.0682e-01,  9.9087e-03,  ..., -1.1775e-01,\n",
       "          -2.0251e-01, -3.3115e-01],\n",
       "         [ 4.1339e-01,  8.4770e-02,  1.2837e-03,  ...,  4.0821e-01,\n",
       "          -1.6438e-01,  1.2384e-01],\n",
       "         [-5.5205e-02, -5.0865e-01,  2.9354e-01,  ...,  4.7963e-01,\n",
       "          -1.7520e-01, -2.5475e-02],\n",
       "         [ 2.2127e-01,  1.0342e-01, -2.5137e-01,  ...,  3.1584e-01,\n",
       "          -5.5105e-02, -3.1359e-01],\n",
       "         [-7.9030e-02, -1.8711e-01,  6.1984e-02,  ..., -1.1434e-01,\n",
       "          -1.2354e-01, -1.3375e-01]],\n",
       "\n",
       "        [[ 5.2905e-02, -2.6395e-01, -2.0207e-01,  ..., -2.9690e-01,\n",
       "          -5.6637e-02, -5.0725e-02],\n",
       "         [ 3.7682e-01, -1.8872e-01,  3.8592e-01,  ...,  4.4001e-02,\n",
       "          -3.8609e-04,  3.6950e-01],\n",
       "         [-1.1478e-01,  1.0126e-01,  1.5504e-01,  ...,  2.4204e-02,\n",
       "          -1.4982e-01,  6.6195e-02],\n",
       "         [ 1.9947e-01, -2.2834e-01,  3.1641e-01,  ...,  4.5814e-01,\n",
       "          -5.2437e-02, -8.1786e-02],\n",
       "         [ 8.8090e-02,  2.3792e-01, -6.4968e-02,  ..., -1.8648e-01,\n",
       "          -3.3943e-02, -2.2735e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 9.6233e-03,  1.5329e-01,  2.3566e-01,  ..., -5.0566e-02,\n",
       "           4.1958e-01,  2.4529e-01],\n",
       "         [-2.4768e-01,  5.5671e-02, -3.7979e-02,  ..., -4.3241e-01,\n",
       "          -2.4911e-01, -2.7028e-01],\n",
       "         [ 2.1640e-01,  9.0386e-02,  2.2395e-01,  ...,  2.6138e-01,\n",
       "          -1.0001e-01, -2.7728e-01],\n",
       "         [ 1.8337e-02,  2.5636e-01, -5.3120e-02,  ...,  4.1417e-01,\n",
       "           7.3701e-02, -3.9133e-02],\n",
       "         [-2.2251e-01, -1.7144e-01,  2.3460e-01,  ...,  1.6446e-01,\n",
       "          -4.4295e-02,  1.9147e-01]],\n",
       "\n",
       "        [[ 2.8300e-01,  1.0699e-01, -6.9333e-02,  ..., -6.6002e-01,\n",
       "           8.1981e-02, -2.1227e-01],\n",
       "         [ 2.3102e-01,  2.3151e-01, -9.9720e-02,  ...,  5.7686e-02,\n",
       "           3.1050e-01, -1.3086e-01],\n",
       "         [ 1.7396e-01, -3.9617e-01,  1.8523e-01,  ...,  2.1972e-01,\n",
       "          -6.3581e-02, -9.5748e-02],\n",
       "         [ 1.4541e-01, -1.3795e-01, -5.5526e-02,  ...,  9.4149e-02,\n",
       "          -6.5945e-02, -5.9847e-02],\n",
       "         [ 2.4684e-01, -2.7655e-01,  9.4354e-02,  ..., -2.5030e-01,\n",
       "           2.8620e-01, -8.0246e-02]],\n",
       "\n",
       "        [[ 3.2054e-02, -9.8048e-02, -1.0432e-01,  ...,  1.6767e-01,\n",
       "          -2.9065e-01,  7.2968e-02],\n",
       "         [ 8.0188e-03,  2.1525e-01,  2.2751e-01,  ..., -2.0668e-02,\n",
       "          -3.8956e-04,  4.8769e-02],\n",
       "         [ 4.1621e-01,  2.3312e-01,  1.6848e-01,  ...,  9.4038e-02,\n",
       "          -2.2613e-01, -8.4307e-03],\n",
       "         [-2.4866e-01, -2.3536e-02, -1.3127e-01,  ..., -3.6530e-03,\n",
       "           5.2772e-02, -4.2564e-01],\n",
       "         [-4.3766e-01, -5.6205e-03,  4.7792e-01,  ..., -2.3176e-01,\n",
       "          -3.2930e-01,  4.2408e-01]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch API\n",
    "## torch.nn\n",
    "- [torch.nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)ÔºöÂ∫îÁî®Á∫øÊÄßÂèòÊç¢Âà∞ËæìÂÖ•Êï∞ÊçÆÔºöy = xA^T + b\n",
    "\n",
    "## torch\n",
    "- [torch.reshape](https://pytorch.org/docs/stable/generated/torch.reshape.html?highlight=reshape#torch.reshape)ÔºöÂ∞ÜËæìÂÖ•Âº†ÈáèÁöÑÂΩ¢Áä∂ÊîπÂèò‰∏∫ÁªôÂÆöÁöÑÂΩ¢Áä∂\n",
    "- [torch.permute](https://pytorch.org/docs/stable/generated/torch.permute.html?highlight=permute#torch.permute)ÔºöËøîÂõû‰∏Ä‰∏™ËæìÂÖ•Âº†ÈáèÁöÑËßÜÂõæÔºåËØ•ËßÜÂõæÁöÑÁª¥Â∫¶‰ª•ÁâπÂÆöÁöÑÈ°∫Â∫èÈáçÊñ∞ÊéíÂàó\n",
    "- [torch.chunk](https://pytorch.org/docs/stable/generated/torch.chunk.html?highlight=chunk#torch.chunk)ÔºöÂ∞ÜËæìÂÖ•Âº†ÈáèÂàáÂâ≤‰∏∫ÁâπÂÆöÊï∞ÈáèÁöÑÂùó\n",
    "- [torch.matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html?highlight=torch+matmul#torch.matmul)ÔºöÊâßË°å‰∏§‰∏™Âº†Èáè‰πãÈó¥ÁöÑÁü©Èòµ‰πòÊ≥ï\n",
    "- [torch.transpose](https://pytorch.org/docs/stable/generated/torch.transpose.html?highlight=torch+transpose#torch.transpose)ÔºöËøîÂõû‰∏Ä‰∏™ËæìÂÖ•Âº†ÈáèÁöÑËΩ¨ÁΩÆÔºåÂç≥‰∫íÊç¢‰∏§‰∏™Áª¥Â∫¶\n",
    "- [torch.full](https://pytorch.org/docs/stable/generated/torch.transpose.html?highlight=torch+full#torch.full)ÔºöËøîÂõû‰∏Ä‰∏™ÂΩ¢Áä∂‰∏∫ sizeÔºåÂ°´ÂÖÖÂÄº‰∏∫ fill_value ÁöÑÂº†Èáè\n",
    "- [torch.triu](https://pytorch.org/docs/stable/generated/torch.transpose.html?highlight=torch+triu#torch.triu)ÔºöËøîÂõû‰∏Ä‰∏™Âº†ÈáèÔºåÂÖ∂‰∏≠ÂåÖÂê´‰∫ÜËæìÂÖ•Áü©ÈòµÁöÑ‰∏ä‰∏âËßíÈÉ®ÂàÜÔºåÂÖ∂‰ªñ‰ΩçÁΩÆËÆæ‰∏∫0\n",
    "\n",
    "## torch.nn.functional\n",
    "- [torch.nn.functional.softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html?highlight=softmax#torch.nn.functional.softmax)ÔºöÂØπËæìÂÖ•Êï∞ÊçÆËøõË°å softmax Êìç‰ΩúÔºåËøôÊòØ‰∏Ä‰∏™Â∏∏Áî®‰∫éÂ∞ÜÂÆûÊï∞ÂêëÈáèËßÑËåÉÂåñ‰∏∫Ê¶ÇÁéáÂàÜÂ∏ÉÁöÑÊìç‰Ωú"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
